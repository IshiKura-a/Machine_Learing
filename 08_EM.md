# EM：期望最大

## Background

​	EM算法的引出主要是为了解决隐变量的混合模型的参数极大似然估计问题。
$$
	\theta_{\text{MLE}}=\text{argmax}_\theta\log{P(x|\theta)}
$$
​	对于比较简单的问题来说，我们是可以直接通过求导获得参数的解析解的。但是在类似于GMM中，解析解是很难获得的。因此，我们尝试找到一种迭代的方法，来解决此问题。

​	因为
$$
\log{P(x|\theta)}=\log{P(x,z|\theta)}-\log{P(z|x,\theta)}
$$
​	引入一个随机变量$q(z)$，加入到等式右侧，有
$$
\log{P(x|\theta)}=\log{\dfrac{P(x,z|\theta)}{q(z)}}-\log{\dfrac{P(z|x,\theta)}{q(z)}}
$$
​	两边关于$q(z)$求期望，有
$$
\begin{aligned}
	\text{左}&=\int_zq(z)\log{P(x|\theta)}dz \\
	&=\log{P(x|\theta)}\int_zq(z)dz \\
	&=\log{P(x|\theta)} \\
	 \\
	\text{右}&=\int_zq(z)\log{\dfrac{P(x,z|\theta)}{q(z)}}dz \\
	&-\int_zq(z)\log{\dfrac{P(z|x,\theta)}{q(z)}}dz \\
	
\end{aligned}
$$
​	观察右式第二项，实际为关于$q(z)$和$P(z|x,\theta)$的相对熵$KL(q(z)||P(z|x,\theta))$，我们把第一项称作$\text{ELBO}$(Evidence Lower Bound). 因为$KL(p||q)\ge0$，当且仅当$q=p$时取等，所以
$$
\log{P(x|\theta)}\ge\text{ELBO}
$$
​	在$q(z)=P(z|x,\theta)$时，两者相等。因此，有
$$
\begin{aligned}
	\hat{\theta}&=\text{argmax}_\theta\text{ELBO} \\
	&=\text{argmax}_\theta\int_zq(z)\log{\dfrac{P(x,z|\theta)}{q(z)}}dz \\
	&=\text{argmax}_\theta\int_z{P(z|x,\theta^{(t)})}\log{\dfrac{P(x,z|\theta)}{P(z|x,\theta^{(t)})dz}}dz \\
	&=\text{argmax}_\theta\int_z{P(z|x,\theta^{(t)})}\cdot(\log{P}(x,z|\theta)-\log{P(z|x,\theta^{(t)}})dz \\
	&=\text{argmax}_\theta\int_z{P(z|x,\theta^{(t)})}\cdot\log{P}(x,z|\theta)dz
\end{aligned}
$$


## Algorithm

​	EM算法的基本框架如下：
$$
\theta^{(t+1)}=\text{argmax}_\theta\int_z\log{P}(x,z|\theta)\cdot{P(z|x,\theta^{(t)})dz}
$$
​	积分式可以看做一个期望，即
$$
\theta^{(t+1)}=\text{argmax}_\theta{E_{z|x,\theta^{(t)}}}[\log{P}(x,z|\theta)]
$$
​	我们将此公式中求期望的过程称为E步，将参数最大化的过程称为M步。先考虑这个迭代方法是否收敛，要证明它收敛，我们只需证明：
$$
	\theta^{(t)}\rightarrow\theta^{(t+1)}\text{, }\log{P(x|\theta^{(t)})\leq}\log{P(x|\theta^{(t+1)})}
$$
​	对公式$(2)$两边求关于$z|x,\theta^{(t)}$的期望，有
$$
\begin{aligned}
	\text{左}&=\int_zP(z|x,\theta^{(t)})\cdot\log{P(x|\theta)}dz \\
	&=\log{P(x|\theta)}\int_zP(z|x,\theta^{(t)})dz \\
	&=\log{P(x|\theta)} \\
	 \\
	\text{右}&=\int_z\log{P}(x,z|\theta)\cdot{P(z|x,\theta^{(t)})dz} \\
	&-\int_z{P(z|x,\theta^{(t)})}\cdot\log{P(z|x,\theta)}dz \\
\end{aligned}
$$
​	令
$$
\begin{aligned}
	Q(\theta,\theta^{(t)})&=\int_z\log{P}(x,z|\theta)\cdot{P(z|x,\theta^{(t)})dz} \\
	H(\theta,\theta^{(t)})&=\int_z{P(z|x,\theta^{(t)})}\cdot\log{P(z|x,\theta)}dz
\end{aligned}
$$
​	不难发现，
$$
Q(\theta,\theta^{(t)})=E_{z|x,\theta^{(t)}}[\log{P}(x,z|\theta)]
$$
​	根据$(2)$式可得
$$
Q(\theta^{(t+1)},\theta^{(t)})\ge{Q(\theta^{(t)},\theta^{(t)})}
$$
​	另一方面，我们有
$$
\begin{aligned}
	&H(\theta^{(t+1)},\theta^{(t)})-H(\theta^{(t)},\theta^{(t)}) \\
	=&\int_z{P(z|x,\theta^{(t)})}\cdot\log{P(z|x,\theta^{(t+1)})}dz \\
	-&\int_z{P(z|x,\theta^{(t)})}\cdot\log{P(z|x,\theta^{(t)})}dz \\
	=&\int_z{P(z|x,\theta^{(t)})}\cdot\log{\dfrac{P(z|x,\theta^{(t+1)})}{P(z|x,\theta^{(t)})}}dz
\end{aligned}
$$
​	由于$\log(x)$是凹函数，所以由Jensen不等式，有
$$
E\log(x)\le\log{E}(x)
$$
​	因此，
$$
\begin{aligned}
	H(\theta^{(t+1)},\theta^{(t)})-H(\theta^{(t)},\theta^{(t)})
	&\le\log\int_z{P(z|x,\theta^{(t)})}\cdot{\dfrac{P(z|x,\theta^{(t+1)})}{P(z|x,\theta^{(t)})}}dz \\
	&=\log\int_zP(z|x,\theta^{(t+1)})dz \\
	&=0
\end{aligned}
$$
​	因此，
$$
\begin{aligned}
	\log{P}(x|\theta^{(t)})&=Q(\theta^{(t)},\theta^{(t)})-H(\theta^{(t)},\theta^{(t)}) \\
	&\le{Q(\theta^{(t+1)},\theta^{(t)})-H(\theta^{(t+1)},\theta^{(t)})} \\
	&=\log{P(x|\theta^{(t+1)})}
\end{aligned}
$$
​	得证。

### Generalized EM

​	实际情况中，可能后验$P(z|x,\theta)$本身都难以求解，对此需要对狭义的EM算法进行改进，提出广义的EM算法。观察EM算法的推导过程，我们加入了一个新的随机变量$q(z)$,满足
$$
	\log{P(x|\theta)}=\text{ELBO}+\text{KL}(q||p)
$$
​	其中$p$是后验$P(z|x,\theta)$，令
$$
\mathcal{L}(q,\theta)=\text{ELBO}
$$
​	则
$$
\begin{aligned}
	\mathcal{L}(q,\theta)&=E_q[\log{P(x,z|\theta)}-\log{q}] \\
	&=E_q[\log{P(x,z|\theta)}+E[\dfrac{1}{\log{q}}] \\
	&=E_q[\log{P(x,z|\theta)}+H[q]
\end{aligned}
$$
​	其中$H[q]$是$q(z)$的熵。

​	经过之前的推导，$\text{KL}=0$时，$q=p$，又因为$\text{KL}$非负，所以只要$KL$尽可能地小，$q$就可以充分逼近$p$，对此进行参数估计，令
$$
	\hat{q}=\text{argmin}_q\text{KL}(q||p)
$$
​	由于在$\theta$固定时，$(11)$式左侧为定值，所以
$$
	\hat{q}=\text{argmax}_q\mathcal{L}(q,\theta)
$$
​	把$\hat{q}$代入，估计$\theta$，
$$
	\hat{\theta}=\text{argmax}_\theta\mathcal{L}(\hat{q},\theta)
$$
​	因此，广义的EM算法如下
$$
\begin{aligned}
	&\text{E-step: }q^{(t+1)}=\text{argmax }\mathcal{L}(q,\theta^{(t)}) \\
	&\text{M-step: }\theta^{(t+1)}=\text{argmax }\mathcal{L}(q^{(t+1)},\theta)
\end{aligned}
$$
​	比较狭义的EM算法，可以发现在迭代式中，增加了$H[q]$一项，因为在狭义的EM中，我们假定$q(z)$已知，即$H[q]$是一个常数，对$\theta$的估计没有任何影响，所以删去了；但是在广义的EM中，$q$也是估计而来的参数，所以无法忽略。广义的EM算法，又称MM算法(Maximize-Maximize).

## Variant EM

​	观察广义的EM算法，先对$q$估计，再对$\theta$估计，实际上应用了一种坐标上升法的思想。这很容易让人联想到所谓的“梯度上升法”，两者都是优化方法，但是优化的过程并不相同，如下图所示：

![Coordinate Ascent](https://raw.githubusercontent.com/IshiKura-a/Machine_Learing/master/img/8_1.png)

​	在E步$q$无法求的的情况下，我们可以使用变分推断VI(Variational Inference)，就可以得到EM算法的变种VBEM（变分贝叶斯EM），又称VEM（变分EM）。如果使用蒙特卡洛采样法来求得后验分布，就可以得到MCEM。这是比较常见的两种EM的变种。